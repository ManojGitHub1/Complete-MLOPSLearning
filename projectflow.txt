type linting in python
def train_model(X_train: np.ndarray, y_train: np.ndarray, params: dict) -> RandomForestClassifier:
    return clf
X_train of type np.ndarray
params of type dictionary
and return of type classifier


Building Pipeline:
1. add experiments folder (general DS workflow)
2. add src folder along with all components/artifacts(run then individually)
3. add data, models, reports directories to .gitignore file
4. git commit-push

Setting up DVC pipeline (without params):
5. Create dvc.yaml file and add stages to it.
6. dvc init then do "dvc repro" to test the pipeline automation. (use/check "dvc dag" to check graph visually dag(directed acyclic graph))
7. now git add-commit-push

Setting up DVC pipeline (with params)
8. add params.yaml file
9. add params setup (mentioned below)
10. do "dvc repro" again to test the pipeline along with params
11. Now git add-commit-push

Expermients with DVC:
12. pip install dvclive
13. Add the dvclive code block (mentioned below)
14. Do "dvc exp run", it will create a new dvc.yaml(if already not there) and dvclive directory (each run will be considered as an experiment by DVC)
15. Do "dvc exp show" on terminal to see the experiments or use extension on VSCode (install dvc extension)
    apply is used if that exp has performed well and want to
16. Do "dvc exp remove {exp-name}" to remove exp (optional) | "dvc exp apply {exp-name}" to reproduce prev exp
17. Change params, re-run code (produce new experiments)
18. Now git add, commit, push


Adding a remote S3 storage to DVC:
19. login to AWS console
20. create an IAM user (straight forward process)
    access key, secret access key

21. create s3 (enter unique name and create)
22. "pip install dvc[s3]"
23. "pip install awscli"
24. "aws configure" on terminal
    -d <store_name> s3://<bucket_name>
25. dvc remote add -d dvcstore s3://bucketname
26. dvc commit-push the exp outcome that you want to keep
27. Finally git add-commit-push



-------------------------------------------------
Flow
1. creating pipeline
2. configured parameters
3. done experiment tracking
4. reproduce best experiment
5. once best experiment data/params is got, push it.

-- here selecting experiment macro-drab.




---------------------------------------------------------------------------

9. params setup
params.yaml setup
1. import yaml
2. add func:
def load_params(params_path: str) -> dict:
    ...
    ...
3. add to main():
# data_ingestion
params = load_params(params_path='params.yaml')
test_size = params['data_ingestion']['test_size']

# feature_engineering
params = load_params(params_path='params.yaml')
max_features = params['feature_engineering']['max_features']

# model_building
params = load_params('params.yaml')['model_building']

----------------------------------------------------------------------------

dvclive code block:
in model_evaluation
1> import dvclive and yaml:
from dvclive import Live
import yaml
2> Add the load_params function and initiate "params" var in main
3> Add below code block to main:
with Live(save_dvc_exp=True) as live:
    live.log_metric('accuracy', accuracy_score(y_test, y_test))
    live.log_metric('precision', precision_score(y_test, y_test))
    live.log_metric('recall', recall_score(y_test, y_test))

    live.log_params(params)

-----------------------------------------------------------------------------