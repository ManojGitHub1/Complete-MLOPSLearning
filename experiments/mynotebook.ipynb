{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Importing libraries...\n",
      "Libraries imported successfully.\n",
      "\n",
      "Step 2: Ensuring NLTK 'stopwords' are available...\n",
      "'stopwords' data is already available.\n",
      "\n",
      "Step 3: Defining the text transformation function...\n",
      "Alternative text transformation function is ready.\n",
      "\n",
      "Step 4: Loading and cleaning the dataset...\n",
      "Dataset loaded and cleaned. Shape: (5169, 2)\n",
      "\n",
      "Step 5: Preprocessing data...\n",
      "Text transformation and encoding complete.\n",
      "\n",
      "Step 6: Vectorizing data and splitting into train/test sets...\n",
      "Data is ready for model training.\n",
      "\n",
      "Step 7: Training and evaluating all models...\n",
      "\n",
      "Model: SVC\n",
      "  - Accuracy: 0.9739\n",
      "  - Precision: 0.9664\n",
      "\n",
      "Model: KNN\n",
      "  - Accuracy: 0.9033\n",
      "  - Precision: 1.0000\n",
      "\n",
      "Model: NB\n",
      "  - Accuracy: 0.9758\n",
      "  - Precision: 1.0000\n",
      "\n",
      "Model: DT\n",
      "  - Accuracy: 0.9381\n",
      "  - Precision: 0.8364\n",
      "\n",
      "Model: LR\n",
      "  - Accuracy: 0.9555\n",
      "  - Precision: 0.9423\n",
      "\n",
      "Model: RF\n",
      "  - Accuracy: 0.9739\n",
      "  - Precision: 0.9826\n",
      "\n",
      "Model: Adaboost\n",
      "  - Accuracy: 0.9246\n",
      "  - Precision: 0.8409\n",
      "\n",
      "Model: Bgc\n",
      "  - Accuracy: 0.9574\n",
      "  - Precision: 0.8672\n",
      "\n",
      "Model: ETC\n",
      "  - Accuracy: 0.9758\n",
      "  - Precision: 0.9669\n",
      "\n",
      "Model: GBDT\n",
      "  - Accuracy: 0.9497\n",
      "  - Precision: 0.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Downloads\\ML\\Complete-MLOPSLearning\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:20:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: xgb\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9500\n",
      "\n",
      "==================================================\n",
      "All models have been trained and evaluated successfully.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. IMPORTS AND INITIAL SETUP\n",
    "# ==============================================================================\n",
    "print(\"Step 1: Importing libraries...\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# For text processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# All the models to be evaluated\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DOWNLOAD NLTK STOPWORDS\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 2: Ensuring NLTK 'stopwords' are available...\")\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print(\"'stopwords' data is already available.\")\n",
    "except LookupError:\n",
    "    print(\"Downloading 'stopwords' data...\")\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    print(\"'stopwords' downloaded successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TEXT TRANSFORMATION FUNCTION\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 3: Defining the text transformation function...\")\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def transform_text_alternative(text):\n",
    "    \"\"\"\n",
    "    A text transformation function that avoids the problematic nltk.word_tokenize.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    \n",
    "    stemmed_words = []\n",
    "    for word in words:\n",
    "        cleaned_word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "        if cleaned_word.isalnum() and cleaned_word not in stop_words:\n",
    "            stemmed_words.append(ps.stem(cleaned_word))\n",
    "            \n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "print(\"Alternative text transformation function is ready.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. DATA LOADING AND CLEANING\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 4: Loading and cleaning the dataset...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('spam.csv', encoding='latin1')\n",
    "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True, errors='ignore')\n",
    "    df.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\n",
    "    df.drop_duplicates(keep='first', inplace=True)\n",
    "    print(f\"Dataset loaded and cleaned. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'spam.csv' not found. Please ensure it is in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. DATA PREPROCESSING\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 5: Preprocessing data...\")\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "# THIS IS THE CORRECTED LINE:\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "\n",
    "# Apply the reliable transformation function\n",
    "df['transformed_text'] = df['text'].apply(transform_text_alternative)\n",
    "print(\"Text transformation and encoding complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. FEATURE EXTRACTION AND SPLITTING\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 6: Vectorizing data and splitting into train/test sets...\")\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "print(\"Data is ready for model training.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. MODEL TRAINING AND EVALUATION\n",
    "# ==============================================================================\n",
    "print(\"\\nStep 7: Training and evaluating all models...\")\n",
    "\n",
    "clfs = {\n",
    "    'SVC': SVC(kernel=\"sigmoid\", gamma=1.0),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NB': MultinomialNB(),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'LR': LogisticRegression(solver='liblinear', penalty='l1'),\n",
    "    'RF': RandomForestClassifier(n_estimators=50, random_state=2),\n",
    "    'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=2),\n",
    "    'Bgc': BaggingClassifier(n_estimators=50, random_state=2),\n",
    "    'ETC': ExtraTreesClassifier(n_estimators=50, random_state=2),\n",
    "    'GBDT': GradientBoostingClassifier(n_estimators=50, random_state=2),\n",
    "    'xgb': XGBClassifier(n_estimators=50, random_state=2, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy, precision\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"  - Accuracy: {current_accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {current_precision:.4f}\")\n",
    "\n",
    "print(\"\\n==================================================\")\n",
    "print(\"All models have been trained and evaluated successfully.\")\n",
    "print(\"==================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
